{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":7440731,"sourceType":"datasetVersion","datasetId":4330748},{"sourceId":7638924,"sourceType":"datasetVersion","datasetId":4334382}],"dockerImageVersionId":30636,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"! pip install torch==2.1.0  torchvision==0.16.0 torchtext==0.16.0 torchaudio==2.1.0 --index-url https://download.pytorch.org/whl/cu121\n! pip install torch_geometric==2.4\n! pip install pyg_lib torch_scatter torch_sparse torch_cluster torch_spline_conv -f https://data.pyg.org/whl/torch-2.1.0+cu121.html\n! pip install sentence-transformers\n! pip install torcheval\n! pip install matplotlib\n! pip install pandas\n! pip install tensorboard","metadata":{"execution":{"iopub.status.busy":"2024-01-22T15:22:49.842619Z","iopub.execute_input":"2024-01-22T15:22:49.843073Z","iopub.status.idle":"2024-01-22T15:27:04.089575Z","shell.execute_reply.started":"2024-01-22T15:22:49.843034Z","shell.execute_reply":"2024-01-22T15:27:04.088205Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from torch_geometric.data import HeteroData\nimport pandas as pd\nimport numpy as np \nfrom sklearn.metrics import f1_score\nfrom sklearn.metrics import precision_score\nfrom sklearn.metrics import recall_score\n\nimport torch \ndata = torch.load('/kaggle/input/twibot22-pyggraph/TwiBot22_Graph_with_degreecounts_with_y.pt')\n\nfor node_type in data.node_types:\n    data[node_type].x = data[node_type].x.float()\n    \nnode_ids = torch.load('/kaggle/input/twibot22-pyggraph/unique_nodes.pt')\ntest_df = pd.read_csv('/kaggle/input/twibot22-pyggraph/test.csv')\ntest_df = test_df[test_df['user_id'].isin(node_ids)]\ntest_df['index'] = test_df['user_id'].apply(lambda x: node_ids[x])\n","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2024-01-22T15:27:04.092609Z","iopub.execute_input":"2024-01-22T15:27:04.093445Z","iopub.status.idle":"2024-01-22T15:33:01.606757Z","shell.execute_reply.started":"2024-01-22T15:27:04.093398Z","shell.execute_reply":"2024-01-22T15:33:01.605886Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Define GNN Model\nfrom torch_geometric.nn import HGTConv, Linear\n\nfrom torch.nn import functional as F\n\nclass HGT(torch.nn.Module):\n    def __init__(self, hidden_channels, out_channels, num_heads, num_layers, node_types, data_metadata):\n        super().__init__()\n\n        self.lin_dict = torch.nn.ModuleDict()\n        for node_type in node_types:\n            self.lin_dict[node_type] = Linear(-1, hidden_channels)\n\n        self.convs = torch.nn.ModuleList()\n        for _ in range(num_layers):\n            conv = HGTConv(hidden_channels, hidden_channels, data_metadata,\n                           num_heads, group='sum')\n            self.convs.append(conv)\n\n        self.lin = Linear(hidden_channels, out_channels)\n\n    def forward(self, x_dict, edge_index_dict):\n        x_dict = {\n            node_type: self.lin_dict[node_type](x).relu_()\n            for node_type, x in x_dict.items()\n        }\n\n        for conv in self.convs:\n            x_dict = conv(x_dict, edge_index_dict)\n\n        return self.lin(x_dict['user'])\n    \n    \n    \nmodel = HGT(hidden_channels=256, out_channels=1, num_heads=8, num_layers=2, node_types=data.node_types, data_metadata=data.metadata())\n","metadata":{"execution":{"iopub.status.busy":"2024-01-22T15:33:01.608018Z","iopub.execute_input":"2024-01-22T15:33:01.608306Z","iopub.status.idle":"2024-01-22T15:33:01.768373Z","shell.execute_reply.started":"2024-01-22T15:33:01.608282Z","shell.execute_reply":"2024-01-22T15:33:01.767596Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# create minibatch loader\nfrom torch_geometric.loader import HGTLoader\nbatch_size = 32\nnum_node_types = len(data.node_types)\none_hop_neighbors = (20 * batch_size)//num_node_types # per relationship type\ntwo_hop_neighbors = (20 * 8 * batch_size)//num_node_types # per relationship type\n#three_hop_neighbors = (20 * 8 * 3 * batch_size)//num_node_types # per relationship type\nnum_neighbors = [one_hop_neighbors, two_hop_neighbors]\n\n","metadata":{"execution":{"iopub.status.busy":"2024-01-22T15:33:12.187445Z","iopub.execute_input":"2024-01-22T15:33:12.189637Z","iopub.status.idle":"2024-01-22T15:33:12.197318Z","shell.execute_reply.started":"2024-01-22T15:33:12.189606Z","shell.execute_reply":"2024-01-22T15:33:12.196289Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# train model \nfrom tqdm.auto import tqdm\nfrom datetime import datetime\nfrom torch.utils.tensorboard import SummaryWriter\nfrom pathlib import Path\n\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# get weights after training\nimport gc \ndef init(model, state_dict_path):\n    with torch.no_grad():\n        model.eval()\n        for node_type in data.node_types:\n            print(node_type)\n\n            loader = HGTLoader(\n                    data,\n                    # Sample 512 nodes per type and per iteration for 4 iterations\n                    num_samples=num_neighbors,\n                    batch_size=64, #96 or 32 nodes\n                    input_nodes=node_type,\n                    num_workers=0,\n                    pin_memory=True,\n                    prefetch_factor=None,\n                )\n            minibatch = next(iter(loader))\n\n            model(minibatch.x_dict, minibatch.edge_index_dict)\n            model_and_optimizer = torch.load(state_dict_path)\n            model.load_state_dict(model_and_optimizer['model_state_dict'])\n            del loader\n            gc.collect()\n\n\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"del node_ids\ngc.collect()\ndata = data.cuda()\n\n\nmodel.cuda()\nwith open('/kaggle/working/scores.csv', 'w') as csv_file:\n    csv_file.write('Samplesseen,F1,precision,recall\\n')\n    for path in [\n        '/kaggle/input/twibot22-hgt-models/model_samplesseen6407872.pt',\n        '/kaggle/input/twibot22-hgt-models/model_samplesseen6567872.pt',\n        '/kaggle/input/twibot22-hgt-models/model_samplesseen6727872.pt',\n        '/kaggle/input/twibot22-hgt-models/model_samplesseen6887872.pt',\n        '/kaggle/input/twibot22-hgt-models/model_samplesseen7047872.pt',\n        '/kaggle/input/twibot22-hgt-models/model_samplesseen7175872.pt'\n        \n        \n    ]:\n        print('Loading state dict:',path)\n\n        init(model,path)\n        test_loader = HGTLoader(\n            data,\n            num_samples=num_neighbors,\n            batch_size=32,\n            input_nodes=('user', test_df['index'].values.tolist()),  # in testing the model can see the training user nodes, but only test nodes are used for testing\n            num_workers=4,\n            pin_memory=True,\n            prefetch_factor=2,\n            shuffle=True\n        )\n\n        with torch.no_grad():\n            model.eval()\n            y_hat = []\n            y = []\n            for i,minibatch in tqdm(enumerate(test_loader)):\n                out = model(minibatch.x_dict, minibatch.edge_index_dict)\n                yhat_b = (out>0).cpu().numpy()\n                y_b = minibatch['user'].y.unsqueeze(1).float().cpu().numpy()\n                print(i, f1_score(yhat_b, y_b), end='\\r')\n                y_hat.append(yhat_b)\n                y.append(y_b)\n\n            y_hat = np.concatenate(y_hat)\n            y = np.concatenate(y)\n            print('')\n            f1= f1_score(y_hat, y)\n            samplesseen = int(path.replace('/kaggle/input/twibot22-hgt-models/model_samplesseen','').replace('.pt',''))\n            print('final',f1, 'samplesseen',samplesseen)\n            print('')\n            precision = precision_score(y_hat,y)\n            recall = recall_score(y_hat,y)\n            csv_file.write(f'{samplesseen},{f1},{precision},{recall}\\n')\n\n        del test_loader","metadata":{"execution":{"iopub.status.busy":"2024-01-22T15:40:30.424222Z","iopub.execute_input":"2024-01-22T15:40:30.425089Z"},"trusted":true},"execution_count":null,"outputs":[]}]}